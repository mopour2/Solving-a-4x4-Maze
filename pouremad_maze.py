#Mohammad Reza pour Emad
# 11-14-2025
from collections import deque
import json
import math
import os
import cv2, numpy as np, heapq, time, csv, serial.tools.list_ports
from pydobot import Dobot
#--------------------------
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs.play import play
import os
import sounddevice as sd
from scipy.io.wavfile import write
import tempfile
from openai import OpenAI
import json
import time
import re

# ======= Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ =======
TextGlobal = None
State = 1
SAMPLE_RATE = 16000
DURATION = 4
start_color = "green"
Flag_Exit = 0
Flag_Voice_Text= 2# 1= Voice  2 =Txet ChatGPT
FlagFileImag=2
Z_Safe= -20
 #============================ Dobot Setup ============================
try:
    from pydobot import Dobot
except Exception:
    Dobot = None  # Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ø¨Ø¯ÙˆÙ† Ø±Ø¨Ø§Øª Ù‡Ù… Ø§Ø¬Ø±Ø§ Ùˆ Ù…Ø³ÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´ÙˆØ¯
#-------------------------------------------------------------------------
CAMERA_PORT = 2
DOBOT_PORT = "/dev/ttyACM0"   # ÙˆÛŒÙ†Ø¯ÙˆØ²: "COM3" | Ù„ÛŒÙ†ÙˆÚ©Ø³: "/dev/ttyACM0" ÛŒØ§ "/dev/ttyUSB0"
SAVE_FILE = "vision_robot_homography_4aruco.json"

#------------------------------------------------------------------------
H = None
device = None
mask = None
#-------------------------------------------------------------
# Ø§Ø±ØªÙØ§Ø¹ ØµÙØ­Ù‡â€ŒÛŒ Ù¾Ù„Ø§Ø³ØªÛŒÚ©ÛŒ (Ø¹Ù…Ù‚ ØªÙ…Ø§Ø³ Ù‚Ù„Ù…/Ø§Ù†Ø¯Ø§ÙÚ©ØªÙˆØ±) â€” Ø­ØªÙ…Ø§Ù‹ Ø¨Ø§ Ø³ØªØ§Ù¾ Ø®ÙˆØ¯ØªØ§Ù† Sync Ú©Ù†ÛŒØ¯
BOARD_Z   = -47                 # Ø§Ø±ØªÙØ§Ø¹ ØªÙ‚Ø±ÛŒØ¨ÛŒ ØµÙØ­Ù‡ (Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ú©Ø¯Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø´Ù…Ø§)
PATH_Z    = BOARD_Z + 15        # 15 Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ± Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² ØµÙØ­Ù‡ (Ø¯Ø± Ø¨Ø§Ø²Ù‡ 10..20 mm)
TRAVEL_Z  = BOARD_Z + 40        # Ø§Ø±ØªÙØ§Ø¹ Ø§Ù…Ù†â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¬Ø§Ø¨Ø¬Ø§ÛŒÛŒ Ø¨ÛŒÙ† Ù†Ù‚Ø§Ø·
TOOL_R    = 0                   # Ø²Ø§ÙˆÛŒÙ‡ R Ø§Ù†Ø¯Ø§ÙÚ©ØªÙˆØ±Ø› 0 Ú©Ø§ÙÛŒ Ø§Ø³Øª

HOME      = (220, 0, 150, TOOL_R)  # Ø®Ø§Ù†Ù‡â€ŒÛŒ Ø§Ù…Ù†
SPEED_XY  = 70
SPEED_Z   = 70
# =================== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ ===================
WARP_SIZE_X =640 -1
WARP_SIZE_Y =480 -1

KERNEL_SIZE = 1
DILATE_ITER = 1
SMOOTH_WINDOW = 5
SAFE_MARGIN_PX = 10   # ÙØ§ØµÙ„Ù‡ Ø§ÛŒÙ…Ù† Ø§Ø² Ø¯ÛŒÙˆØ§Ø± (Ù¾ÛŒÚ©Ø³Ù„)
REPULSION_STRENGTH = 10
CENTER_WEIGHT = 7.0
Margin_for_delet = 10
# âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙÛŒØ²ÛŒÚ©ÛŒ Ù…Ø§Ø² Ø±ÙˆÛŒ Ù…ÛŒØ² Dobot
ORIGIN_XY = (300, 5)
CELL_SIZE_MM = 37.5
BOARD_Z = -47
PATH_Z = BOARD_Z + 20



#-------------------------------------------------------------------------------

def find_gate_wall_follow_visual_v5(maze, start, show=True, max_depth=20000):
    """
    Ù…Ù†Ø·Ù‚:
    1) Ø§Ø² start ØªØ§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ø¯ÛŒÙˆØ§Ø± Ø¨Ø±Ùˆ (BFS).
    2) Ø¯ÛŒÙˆØ§Ø± Ø±Ø§ Ø¯Ø± Ú†Ù‡Ø§Ø± Ø¬Ù‡Øª Ø§Ù…ØªØ¯Ø§Ø¯ Ø¨Ø¯Ù‡Ø› Ø·ÙˆÙ„ Ùˆ Ù†Ù‚Ø·Ù‡â€ŒÛŒ Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ Ù‡Ø± Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· Ø±Ø§ Ù†Ú¯Ù‡ Ø¯Ø§Ø±.
    3) Ø§ÙˆÙ„ Ø¯Ø± Ø±Ø§Ø³ØªØ§ÛŒ Ø§ØµÙ„ÛŒ (Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±: Ø§ÙÙ‚ÛŒ/Ø¹Ù…ÙˆØ¯ÛŒ) ØªÙ„Ø§Ø´ Ú©Ù†: Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ø§Ù†ØªÙ‡Ø§ÛŒ Ø¢Ù†ØŒ Ø¯Ø± Ù‡Ù…Ø§Ù† Ø±Ø§Ø³ØªØ§ ÙˆØ§Ø±Ø¯ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø´Ùˆ Ùˆ ØªØ§ Ø¯ÛŒÙˆØ§Ø± Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±ÙˆØ› Ø§Ú¯Ø± ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ù¾ÛŒØ¯Ø§ Ø´Ø¯ ÙˆØ³Ø·Ø´ = Gate.
    4) Ø§Ú¯Ø± Ø¯Ø± Ø¯Ùˆ Ø¬Ù‡ØªÙ Ø±Ø§Ø³ØªØ§ÛŒ Ø§ØµÙ„ÛŒ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯:
       - Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ØŒ
       - Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ Ù‡Ù…Ø§Ù† Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· Ø¨Ø§ÛŒØ³ØªØŒ
       - Ú¯ÙˆØ´Ù‡ Ø¨Ø²Ù† (Ú†Ø±Ø®Ø´ Û¹Û° Ø¯Ø±Ø¬Ù‡) Ùˆ Ø§Ù…ØªØ¯Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¯ÛŒÙˆØ§Ø± Ø±Ø§ Ø¯Ù†Ø¨Ø§Ù„ Ú©Ù†ØŒ
       - Ø³Ù¾Ø³ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¯Ø± Ù‡Ù…Ø§Ù† Ø±Ø§Ø³ØªØ§ ÙˆØ§Ø±Ø¯ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø´Ùˆ Ùˆ Gate Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†.
    Ù†Ù…Ø§ÛŒØ´: Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ = Ù‚Ø±Ù…Ø²ØŒ Gate = Ø³Ø¨Ø².
    """
    h, w = maze.shape
    vis = cv2.cvtColor((maze * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)

    def is_valid(y, x):
        return 0 <= y < h and 0 <= x < w

    def show_pt(y, x, color=(0,0,255), wait=1):
        if not is_valid(y, x): return
        vis[y, x] = color
        if show:
            cv2.imshow("Gate Finder", vis); cv2.waitKey(wait)

    # ---------- 1) Ø¨Ø±Ùˆ ØªØ§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ø¯ÛŒÙˆØ§Ø± ----------
    from collections import deque
    q = deque([start])
    visited = {start}
    first_wall = None
    while q and len(visited) < max_depth:
        y, x = q.popleft()
        show_pt(y, x, (0,0,255), 1)
        if maze[y, x] == 0:
            first_wall = (y, x); break
        for dy, dx in [(-1,0),(1,0),(0,-1),(0,1)]:
            ny, nx = y+dy, x+dx
            if is_valid(ny,nx) and (ny,nx) not in visited:
                visited.add((ny,nx)); q.append((ny,nx))

    if first_wall is None:
        print("âŒ Ø¯ÛŒÙˆØ§Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."); return None

    wy, wx = first_wall

    # ---------- Ú©Ù…Ú©: Ø§Ù…ØªØ¯Ø§Ø¯ Ø¯ÛŒÙˆØ§Ø± Ø¯Ø± ÛŒÚ© Ø¬Ù‡Øª ----------
    def extend_wall(y, x, dy, dx):
        """ØªØ§ ÙˆÙ‚ØªÛŒ 0 Ø§Ø³Øª Ø­Ø±Ú©Øª Ú©Ù†Ø› Ù†Ù‚Ø§Ø· Ùˆ Ø§Ù†ØªÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· Ø±Ø§ Ø¨Ø¯Ù‡."""
        pts = []
        while is_valid(y, x) and maze[y, x] == 0:
            pts.append((y, x))
            show_pt(y, x, (0,0,255), 1)
            y += dy; x += dx
        end = pts[-1] if pts else (None, None)
        return pts, end  # (ÙÙ‡Ø±Ø³Øª Ù†Ù‚Ø§Ø· Ù¾Ø§Ø±Ù‡â€ŒØ®Ø·ØŒ Ø§Ù†ØªÙ‡Ø§)

    # Ú†Ù‡Ø§Ø± Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ø² Ù†Ù‚Ø·Ù‡Ù” Ø¨Ø±Ø®ÙˆØ±Ø¯
    up_pts,   up_end   = extend_wall(wy, wx, -1, 0)
    down_pts, down_end = extend_wall(wy, wx,  1, 0)
    left_pts, left_end = extend_wall(wy, wx,  0,-1)
    right_pts, right_end=extend_wall(wy, wx,  0, 1)

    # Ø·ÙˆÙ„â€ŒÙ‡Ø§ Ùˆ Ø§Ù†ØªÙ‡Ø§Ù‡Ø§
    segs = {
        "up":    {"len": len(up_pts),    "end": up_end,    "dir":(-1,0)},
        "down":  {"len": len(down_pts),  "end": down_end,  "dir":( 1,0)},
        "left":  {"len": len(left_pts),  "end": left_end,  "dir":( 0,-1)},
        "right": {"len": len(right_pts), "end": right_end, "dir":( 0, 1)},
    }

    vert_total = segs["up"]["len"] + segs["down"]["len"]
    hori_total = segs["left"]["len"] + segs["right"]["len"]
    main_axis  = "vertical" if vert_total >= hori_total else "horizontal"

    # ---------- Ú©Ù…Ú©: Ø­Ø±Ú©Øª Ø¯Ø± ÙØ¶Ø§ÛŒ Ø¨Ø§Ø²Ù Â«Ù¾Ø³ Ø§Ø² Ø§Ù†ØªÙ‡Ø§ÛŒ Ø¯ÛŒÙˆØ§Ø±Â» ØªØ§ Ø¯ÛŒÙˆØ§Ø± Ø¨Ø¹Ø¯ÛŒ ----------
    def walk_free_from(end_pt, dy, dx):
        """Ø§Ø² Ø§Ù†ØªÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ù‡â€ŒØ®Ø·ØŒ ÛŒÚ© Ù¾ÛŒÚ©Ø³Ù„ Ø¬Ù„ÙˆØªØ± ÙˆØ§Ø±Ø¯ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø´Ùˆ Ùˆ ØªØ§ Ø¨Ø±Ø®ÙˆØ±Ø¯ Ø¯ÛŒÙˆØ§Ø± Ø¨Ø±ÙˆØ› Ù„ÛŒØ³Øª ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø±Ø§ Ø¨Ø¯Ù‡."""
        if end_pt[0] is None: return []
        y, x = end_pt[0]+dy, end_pt[1]+dx
        free = []
        while is_valid(y, x) and maze[y, x] == 1:
            free.append((y, x))
            show_pt(y, x, (0,0,255), 1)
            y += dy; x += dx
        return free

    # ---------- 3) Ø§ÙˆÙ„ Ø¯Ø± Ø±Ø§Ø³ØªØ§ÛŒ Ø§ØµÙ„ÛŒ ØªÙ„Ø§Ø´ Ú©Ù† (Ø¯Ùˆ Ø¬Ù‡ØªØ´) ----------
    def try_main_axis():
        if main_axis == "vertical":
            # Ø¨Ø§Ù„Ø§/Ù¾Ø§ÛŒÛŒÙ† â†’ Ø³Ù¾Ø³ Ù‡Ù…Ø§Ù† Ø±Ø§Ø³ØªØ§ Ø¨Ù‡ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø²
            free1 = walk_free_from(segs["up"]["end"],   -1, 0)
            if free1:
                return free1
            free2 = walk_free_from(segs["down"]["end"],  1, 0)
            return free2
        else:
            free1 = walk_free_from(segs["left"]["end"],  0, -1)
            if free1:
                return free1
            free2 = walk_free_from(segs["right"]["end"], 0,  1)
            return free2

    free_line = try_main_axis()

    # ---------- 4) Ø§Ú¯Ø± Ø¯Ø± Ø±Ø§Ø³ØªØ§ÛŒ Ø§ØµÙ„ÛŒ Ù‡ÛŒÚ† ÙØ¶Ø§ÛŒ Ø¨Ø§Ø²ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯:
    #     Â«Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù¾Ø§Ø±Ù‡â€ŒØ®Ø·Â» Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ØŒ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒØ´ Ø¨Ø§ÛŒØ³ØªØŒ Ú¯ÙˆØ´Ù‡ Ø¨Ø²Ù† (Û¹Û°Â°) Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†.
    if not free_line:
        # Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· ÙˆØ§Ù‚Ø¹ÛŒ (len>0)
        nonzero = [(k,v) for k,v in segs.items() if v["len"]>0]
        if not nonzero:
            print("âš ï¸ Ù‡ÛŒÚ† Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ø§Ø² Ø¯ÛŒÙˆØ§Ø± Ù†Ø¯Ø§Ø±ÛŒÙ…."); return None
        shortest_key, shortest = min(nonzero, key=lambda kv: kv[1]["len"])
        end_y, end_x = shortest["end"]; sdy, sdx = shortest["dir"]

        # Ú¯ÙˆØ´Ù‡ Ø²Ø¯Ù†: Ú†Ø±Ø®Ø´ Û¹Û° Ø¯Ø±Ø¬Ù‡ Ø±ÙˆÛŒ Ø§Ù†ØªÙ‡Ø§ÛŒ Ù¾Ø§Ø±Ù‡â€ŒØ®Ø· Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        # Ø§Ú¯Ø± Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ† Ø¹Ù…ÙˆØ¯ÛŒ Ø¨ÙˆØ¯ â†’ Ø§ÙÙ‚ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†ØŒ Ùˆ Ø¨Ø§Ù„Ø¹Ú©Ø³.
        if shortest_key in ["up","down"]:
            # Ø¹Ù…ÙˆØ¯ÛŒ Ø¨ÙˆØ¯ â†’ Ø§ÙÙ‚ÛŒâ€ŒÙ‡Ø§
            cand_dirs = [(0,-1),(0,1)]
        else:
            # Ø§ÙÙ‚ÛŒ Ø¨ÙˆØ¯ â†’ Ø¹Ù…ÙˆØ¯ÛŒâ€ŒÙ‡Ø§
            cand_dirs = [(-1,0),(1,0)]

        # Ø§ÙˆÙ„ Ø§Ù…ØªØ¯Ø§Ø¯ Ø¯ÛŒÙˆØ§Ø± Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ø¬Ù‡Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆØ¯ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†ØŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ù†ØªÙ‡Ø§ÛŒ Ø¢Ù† ÙˆØ§Ø±Ø¯ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø´Ùˆ
        found = []
        for pdy, pdx in cand_dirs:
            # Ø§Ù…ØªØ¯Ø§Ø¯ Ø¯ÛŒÙˆØ§Ø± Ø¯Ø± Ø¬Ù‡Øª Ø¹Ù…ÙˆØ¯ (Ú©Ù†Ø§Ø± Ú¯ÙˆØ´Ù‡)
            wall2_pts, wall2_end = extend_wall(end_y + pdy, end_x + pdx, pdy, pdx)
            if wall2_pts:
                # Ø§Ø² Ø§Ù†ØªÙ‡Ø§ÛŒ Ø¯ÛŒÙˆØ§Ø± Ø¬Ø¯ÛŒØ¯ØŒ Ø¯Ø± Ù‡Ù…Ø§Ù† Ø±Ø§Ø³ØªØ§ ÙˆØ§Ø±Ø¯ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ø´Ùˆ
                free_try = walk_free_from(wall2_end, pdy, pdx)
                if free_try:
                    found = free_try; break
                # Ø§Ú¯Ø± Ø¨Ù„Ø§ÙØ§ØµÙ„Ù‡ ÙØ¶Ø§ÛŒ Ø¨Ø§Ø² Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ø±Ø¹Ú©Ø³ Ù‡Ù…ÛŒÙ† Ø±Ø§Ø³ØªØ§ Ø±Ø§ Ù‡Ù… Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†
                free_try2 = walk_free_from(wall2_end, -pdy, -pdx)
                if free_try2:
                    found = free_try2; break

        free_line = found

    # ---------- Ø®Ø±ÙˆØ¬ÛŒ Gate ----------
    if not free_line:
        print("âš ï¸ ÙØ¶Ø§ÛŒ Ø¢Ø²Ø§Ø¯ Ø¨ÛŒÙ† Ø¯Ùˆ Ø¯ÛŒÙˆØ§Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."); return None

    mid = len(free_line)//2
    gy, gx = free_line[mid]
    show_pt(gy, gx, (0,255,0), 0)
    if show:
        cv2.waitKey(0); cv2.destroyAllWindows()
    print(f"âœ… Gate @ ({gy}, {gx})")
    return (gy, gx)

#-----------------------------------------------------------------
def astar_safe_visual(maze, start, end, show=True):
    """
    Ù†Ø³Ø®Ù‡â€ŒÛŒ ØªØµÙˆÛŒØ±ÛŒ Ø§Ø² A*:
    Ù‡Ø± Ù¾ÛŒÚ©Ø³Ù„ Ú©Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ù‡ Ø±Ù†Ú¯ Ù‚Ø±Ù…Ø² Ø¯Ø± ØªØµÙˆÛŒØ± Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    h, w = maze.shape
    moves = [(-1,0),(1,0),(0,-1),(0,1)]

    # Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒÛŒ Ù†Ù‚Ø´Ù‡ ÙØ§ØµÙ„Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø±
    dist = cv2.distanceTransform((maze*255).astype(np.uint8), cv2.DIST_L2, 5)
    dist = cv2.GaussianBlur(dist, (9,9), 0)
    dist_norm = cv2.normalize(dist, None, 0.0, 1.0, cv2.NORM_MINMAX)
    wall_cost = np.exp(-CENTER_WEIGHT * dist_norm)

    # Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±Ù†Ú¯ÛŒ (RGB)
    vis = cv2.cvtColor((maze * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)

    open_set = [(0, start)]
    came_from = {}
    g = {start: 0}
    f = {start: np.linalg.norm(np.array(start) - np.array(end))}

    while open_set:
        _, current = heapq.heappop(open_set)

        # Ø§Ú¯Ø± Ø¨Ù‡ Ù‡Ø¯Ù Ø±Ø³ÛŒØ¯ÛŒÙ… â†’ Ù…Ø³ÛŒØ± Ø¨Ø³Ø§Ø² Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
        if current == end:
            path = []
            while current in came_from:
                path.append(current)
                current = came_from[current]
            path.append(start)
            path.reverse()

            # Ù…Ø³ÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ø¨ÛŒ
            for (y, x) in path:
                vis[y, x] = (255, 0, 0)
                if show:
                    cv2.imshow("A* Path Progress", vis)
                    cv2.waitKey(15)
            if show:
                cv2.waitKey(0)
                cv2.destroyAllWindows()
            return path, dist

        # Ù‡Ù…Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§
        for dx, dy in moves:
            nx, ny = current[0]+dx, current[1]+dy
            if 0 <= nx < h and 0 <= ny < w and maze[nx, ny] == 1:

                penalty = 1.0 + 6 * wall_cost[nx, ny]
                if dist[nx, ny] < SAFE_MARGIN_PX:
                    penalty += (SAFE_MARGIN_PX - dist[nx, ny]) * 2

                new_g = g[current] + penalty
                if (nx, ny) not in g or new_g < g[(nx, ny)]:
                    g[(nx, ny)] = new_g
                    f_val = new_g + np.linalg.norm(np.array([nx, ny]) - np.array(end))
                    heapq.heappush(open_set, (f_val, (nx, ny)))
                    came_from[(nx, ny)] = current

                    # ğŸ¨ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒÚ©Ø³Ù„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ (Ù‚Ø±Ù…Ø²)
                    vis[nx, ny] = (0, 0, 255)
                    if show:
                        cv2.imshow("A* Path Progress", vis)
                        key = cv2.waitKey(1) & 0xFF
                        if key == 27:
                         cv2.destroyAllWindows()
                         return None, dist
    if show:
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    return None, dist

#=================== ØªØ§Ø¨Ø¹ A* Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ ===================
def astar_safe_visual2(maze, start, end, show=True):
    """
    Ù†Ø³Ø®Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ A* Ø¨Ø§ Distance Transform Ùˆ Ø¯Ø§ÙØ¹Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø±Ù‡Ø§.
    """
 

    h, w = maze.shape
    moves = [(-1,0),(1,0),(0,-1),(0,1)]
    dist = cv2.distanceTransform((maze*255).astype(np.uint8), cv2.DIST_L2, 5)
    dist = cv2.GaussianBlur(dist, (9,9), 0)
    dist_norm = cv2.normalize(dist, None, 0.0, 1.0, cv2.NORM_MINMAX)

# Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø±Ù†Ú¯ÛŒ (RGB)
    vis = cv2.cvtColor((maze * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)

    wall_cost = np.exp(-CENTER_WEIGHT * dist_norm)  # Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù‡ Ø¯ÛŒÙˆØ§Ø± = Ù‡Ø²ÛŒÙ†Ù‡ Ø²ÛŒØ§Ø¯
    open_set = [(0, start)]
    came_from = {}
    g = {start: 0}
    f = {start: np.linalg.norm(np.array(start) - np.array(end))}
    edge_penalty = 0.0
    while open_set:
        _, current = heapq.heappop(open_set)
        if current == end:
            path = []
            while current in came_from:
                path.append(current)
                current = came_from[current]
            path.append(start)
            path.reverse()
            
             # Ù…Ø³ÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ø¨ÛŒ
            for (y, x) in path:
                vis[y, x] = (255, 0, 0)
                if show:
                    cv2.imshow("A* Path Progress", vis)
                    cv2.waitKey(15)
            if show:
                cv2.waitKey(0)
                cv2.destroyAllWindows()
            return path, dist
        
        for dx, dy in moves:
            nx, ny = current[0]+dx, current[1]+dy
            if 0 <= nx < h and 0 <= ny < w and maze[nx, ny] == 1:
                
                if dist[nx, ny] == 0:
                  edge_penalty = 0.0
                  if (nx < BORDER_BAN_WIDTH or ny < BORDER_BAN_WIDTH or
                         nx >= h - BORDER_BAN_WIDTH or ny >= w - BORDER_BAN_WIDTH):
                      edge_penalty = 1000.0  # Ø¬Ø±ÛŒÙ…Ù‡Ù” Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯
                penalty = 1.0 + 6 * wall_cost[nx, ny] + edge_penalty
                # ÙØ§ØµÙ„Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø± â€” Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ø§ÛŒÙ…Ù† Ø§Ø³Øª â†’ Ù‡Ø²ÛŒÙ†Ù‡ Ø²ÛŒØ§Ø¯
                #penalty = 1.0 + 6 * wall_cost[nx, ny]
                if dist[nx, ny] < SAFE_MARGIN_PX:
                    penalty += (SAFE_MARGIN_PX - dist[nx, ny]) * 2

                # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ø±ÛŒØ¯Ù† Ú¯ÙˆØ´Ù‡
                if current in came_from:
                    px, py = came_from[current]
                    if (dx, dy) != (current[0]-px, current[1]-py):
                        penalty += 1.0

                new_g = g[current] + penalty
                if (nx, ny) not in g or new_g < g[(nx, ny)]:
                    g[(nx, ny)] = new_g
                    f_val = new_g + np.linalg.norm(np.array([nx,ny]) - np.array(end))
                    heapq.heappush(open_set, (f_val, (nx, ny)))
                    came_from[(nx, ny)] = current
                 
                  # ğŸ¨ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒÚ©Ø³Ù„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ (Ù‚Ø±Ù…Ø²)
                    vis[nx, ny] = (0, 0, 255)
                    if show:
                        cv2.imshow("A* Path Progress", vis)
                        key = cv2.waitKey(2) & 0xFF
                        if key == 27:
                         cv2.destroyAllWindows()
                         return None, dist
    if show:
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    return None, dist
 #=================== ØªØ§Ø¨Ø¹ A* Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ ===================
def astar_safe2(maze, start, end):
    """
    Ù†Ø³Ø®Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ A* Ø¨Ø§ Distance Transform Ùˆ Ø¯Ø§ÙØ¹Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø±Ù‡Ø§.
    """
    h, w = maze.shape
    moves = [(-1,0),(1,0),(0,-1),(0,1)]
    dist = cv2.distanceTransform((maze*255).astype(np.uint8), cv2.DIST_L2, 5)
    dist = cv2.GaussianBlur(dist, (9,9), 0)
    dist_norm = cv2.normalize(dist, None, 0.0, 1.0, cv2.NORM_MINMAX)

    wall_cost = np.exp(-CENTER_WEIGHT * dist_norm)  # Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù‡ Ø¯ÛŒÙˆØ§Ø± = Ù‡Ø²ÛŒÙ†Ù‡ Ø²ÛŒØ§Ø¯
    open_set = [(0, start)]
    came_from = {}
    g = {start: 0}
    f = {start: np.linalg.norm(np.array(start) - np.array(end))}
    edge_penalty = 0.0
    while open_set:
        _, current = heapq.heappop(open_set)
        if current == end:
            path = []
            while current in came_from:
                path.append(current)
                current = came_from[current]
            path.append(start)
            path.reverse()
            return path, dist

        for dx, dy in moves:
            nx, ny = current[0]+dx, current[1]+dy
            if 0 <= nx < h and 0 <= ny < w and maze[nx, ny] == 1:
                
                if dist[nx, ny] == 0:
                  edge_penalty = 0.0
                  if (nx < BORDER_BAN_WIDTH or ny < BORDER_BAN_WIDTH or
                         nx >= h - BORDER_BAN_WIDTH or ny >= w - BORDER_BAN_WIDTH):
                      edge_penalty = 1000.0  # Ø¬Ø±ÛŒÙ…Ù‡Ù” Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯
                penalty = 1.0 + 6 * wall_cost[nx, ny] + edge_penalty
                # ÙØ§ØµÙ„Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø± â€” Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ø§ÛŒÙ…Ù† Ø§Ø³Øª â†’ Ù‡Ø²ÛŒÙ†Ù‡ Ø²ÛŒØ§Ø¯
                #penalty = 1.0 + 6 * wall_cost[nx, ny]
                if dist[nx, ny] < SAFE_MARGIN_PX:
                    penalty += (SAFE_MARGIN_PX - dist[nx, ny]) * 2

                # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ø±ÛŒØ¯Ù† Ú¯ÙˆØ´Ù‡
                if current in came_from:
                    px, py = came_from[current]
                    if (dx, dy) != (current[0]-px, current[1]-py):
                        penalty += 1.0

                new_g = g[current] + penalty
                if (nx, ny) not in g or new_g < g[(nx, ny)]:
                    g[(nx, ny)] = new_g
                    f_val = new_g + np.linalg.norm(np.array([nx,ny]) - np.array(end))
                    heapq.heappush(open_set, (f_val, (nx, ny)))
                    came_from[(nx, ny)] = current
    return None, dist

# =================== ØªØ§Ø¨Ø¹ A* Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ ===================
def astar_safe(maze, start, end):
    """
    Ù†Ø³Ø®Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ A* Ø¨Ø§ Distance Transform Ùˆ Ø¯Ø§ÙØ¹Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø±Ù‡Ø§.
    """
    h, w = maze.shape
    moves = [(-1,0),(1,0),(0,-1),(0,1)]
    dist = cv2.distanceTransform((maze*255).astype(np.uint8), cv2.DIST_L2, 5)
    dist = cv2.GaussianBlur(dist, (9,9), 0)
    dist_norm = cv2.normalize(dist, None, 0.0, 1.0, cv2.NORM_MINMAX)

    wall_cost = np.exp(-CENTER_WEIGHT * dist_norm)  # Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù‡ Ø¯ÛŒÙˆØ§Ø± = Ù‡Ø²ÛŒÙ†Ù‡ Ø²ÛŒØ§Ø¯
    open_set = [(0, start)]
    came_from = {}
    g = {start: 0}
    f = {start: np.linalg.norm(np.array(start) - np.array(end))}

    while open_set:
        _, current = heapq.heappop(open_set)
        if current == end:
            path = []
            while current in came_from:
                path.append(current)
                current = came_from[current]
            path.append(start)
            path.reverse()
            return path, dist

        for dx, dy in moves:
            nx, ny = current[0]+dx, current[1]+dy
            if 0 <= nx < h and 0 <= ny < w and maze[nx, ny] == 1:
                
                if dist[nx, ny] == 0:
                  continue

                # ÙØ§ØµÙ„Ù‡ Ø§Ø² Ø¯ÛŒÙˆØ§Ø± â€” Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯ Ø§ÛŒÙ…Ù† Ø§Ø³Øª â†’ Ù‡Ø²ÛŒÙ†Ù‡ Ø²ÛŒØ§Ø¯
                penalty = 1.0 + 6 * wall_cost[nx, ny]
                if dist[nx, ny] < SAFE_MARGIN_PX:
                    penalty += (SAFE_MARGIN_PX - dist[nx, ny]) * 2

                # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ø±ÛŒØ¯Ù† Ú¯ÙˆØ´Ù‡
                if current in came_from:
                    px, py = came_from[current]
                    if (dx, dy) != (current[0]-px, current[1]-py):
                        penalty += 1.0

                new_g = g[current] + penalty
                if (nx, ny) not in g or new_g < g[(nx, ny)]:
                    g[(nx, ny)] = new_g
                    f_val = new_g + np.linalg.norm(np.array([nx,ny]) - np.array(end))
                    heapq.heappush(open_set, (f_val, (nx, ny)))
                    came_from[(nx, ny)] = current
    return None, dist

# =================== Smooth Path Function ===================
def smooth_path(path, window=5):
    if len(path) < window:
        return path
    smoothed = []
    for i in range(len(path)):
        y_vals = [path[j][0] for j in range(max(0,i-window), min(len(path),i+window))]
        x_vals = [path[j][1] for j in range(max(0,i-window), min(len(path),i+window))]
        smoothed.append((int(np.mean(y_vals)), int(np.mean(x_vals))))
    return smoothed
#======================================================================
def compress_straight_segments(path_px):
    """
    ÙˆØ±ÙˆØ¯ÛŒ: path_px Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ù†Ù‚Ø§Ø· Ù¾ÛŒÚ©Ø³Ù„ÛŒ Ø¨Ù‡ ÙØ±Ù… [(y,x), (y,x), ...]
    Ø®Ø±ÙˆØ¬ÛŒ: ÙÙ‚Ø· Ù†Ù‚Ø§Ø·Ù ØªØºÛŒÛŒØ± Ø¬Ù‡Øª + Ø§ÙˆÙ„ÛŒÙ† Ùˆ Ø¢Ø®Ø±ÛŒÙ† Ù†Ù‚Ø·Ù‡ (Ù†Ù‚Ø§Ø· ÙˆØ³Ø·Ù Ø®Ø·ÙˆØ· Ù…Ø³ØªÙ‚ÛŒÙ… Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯)
    """
    if not path_px or len(path_px) < 3:
        return path_px[:]

    keep = [path_px[0]]
    # Ø¬Ù‡Øª Ú¯Ø§Ù… Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± Ø¨Ø§ Ù…Ø¤Ù„ÙÙ‡â€ŒÙ‡Ø§ÛŒ -1/0/1 Ù†Ú¯Ø§Ø´Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    dy_prev = path_px[1][0] - path_px[0][0]
    dx_prev = path_px[1][1] - path_px[0][1]
    dir_prev = (np.sign(dy_prev), np.sign(dx_prev))

    for i in range(1, len(path_px) - 1):
        dy = path_px[i+1][0] - path_px[i][0]
        dx = path_px[i+1][1] - path_px[i][1]
        dir_now = (np.sign(dy), np.sign(dx))

        # Ø§Ú¯Ø± Ø¬Ù‡Øª Ø¹ÙˆØ¶ Ø´Ø¯ØŒ Ø§ÛŒÙ† Ù†Ù‚Ø·Ù‡ ÛŒÚ© Â«Ù†Ù‚Ø·Ù‡â€ŒÛŒ Ø´Ú©Ø³Øª/Ú†Ø±Ø®Ø´Â» Ø§Ø³Øª Ùˆ Ø¨Ø§ÛŒØ¯ Ø­ÙØ¸ Ø´ÙˆØ¯
        if dir_now != dir_prev:
            keep.append(path_px[i])
            dir_prev = dir_now

    keep.append(path_px[-1])
    return keep

# =================== Utility Functions ===================


def find_token_center(img, color):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    if color == "green":
        lower, upper = np.array([35,50,50]), np.array([85,255,255])
        mask = cv2.inRange(hsv, lower, upper)
    else:
        lower1, upper1 = np.array([0, 70, 40]),  np.array([15, 255, 255])
        lower2, upper2 = np.array([160, 70, 40]), np.array([180, 255, 255])

        mask = cv2.bitwise_or(cv2.inRange(hsv, lower1, upper1),
                              cv2.inRange(hsv, lower2, upper2))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, np.ones((5,5), np.uint8))
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        M = cv2.moments(c)
        area = cv2.contourArea(c)
        if M["m00"] != 0 and area > 0:
            cx, cy = int(M["m10"]/M["m00"]), int(M["m01"]/M["m00"])
            r = int(max(8, np.sqrt(area/np.pi)))
            return (cx, cy), mask, r
    return None, mask, None


import cv2
import numpy as np

def find_token_center_and_draw(img):
    frame = img.copy()
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # ====== Red Detection ======
    lower1, upper1 = np.array([0, 50, 40]), np.array([15, 255, 255])
    lower2, upper2 = np.array([160, 50, 40]), np.array([180, 255, 255])
    mask1 = cv2.inRange(hsv, lower1, upper1)
    mask2 = cv2.inRange(hsv, lower2, upper2)
    red_mask = cv2.bitwise_or(mask1, mask2)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))

    red_center = None
    cnts, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        (rx, ry), rr = cv2.minEnclosingCircle(c)
        if rr > 3:
            red_center = (int(rx), int(ry))
            cv2.circle(frame, red_center, int(rr), (0, 0, 255), 2)   # ğŸ”´ Ø¯Ø§ÛŒØ±Ù‡ Ù‚Ø±Ù…Ø² Ø¯ÙˆØ±Ø´ Ø¨Ú©Ø´
            cv2.circle(frame, red_center, 3, (0, 0, 255), -1)       # Ù†Ù‚Ø·Ù‡â€ŒÛŒ Ù…Ø±Ú©Ø²

    # ====== Green Detection ======
    v_mean = np.mean(hsv[:, :, 2])
    if v_mean > 180:
        s_min, v_min = 10, 40
        h_low, h_high = 25, 95
    elif v_mean < 80:
        s_min, v_min = 40, 30
        h_low, h_high = 35, 90
    else:
        s_min, v_min = 25, 35
        h_low, h_high = 30, 90

    green_mask = cv2.inRange(hsv, np.array([h_low, s_min, v_min]), np.array([h_high, 255, 255]))
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))

    green_center = None
    cnts, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if cnts:
        possible_centers = []
        for c in cnts:
            (gx, gy), gr = cv2.minEnclosingCircle(c)
            if gr > 3:
                possible_centers.append((int(gx), int(gy)))

        if red_center is not None and possible_centers:
            # Ø¯ÙˆØ±ØªØ±ÛŒÙ† Ø¯Ø§ÛŒØ±Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø±Ù…Ø² Ø±Ø§ Ø³Ø¨Ø² Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±
            dists = [np.linalg.norm(np.array(red_center) - np.array(pt)) for pt in possible_centers]
            green_center = possible_centers[np.argmax(dists)]
            cv2.circle(frame, green_center, int(gr), (0, 255, 0), 2)   # ğŸŸ¢ Ø¯Ø§ÛŒØ±Ù‡ Ø³Ø¨Ø² Ø¯ÙˆØ±Ø´ Ø¨Ú©Ø´
            cv2.circle(frame, green_center, 3, (0, 255, 0), -1)       # Ù†Ù‚Ø·Ù‡â€ŒÛŒ Ù…Ø±Ú©Ø²

    return frame, red_center, green_center


def find_token_center11(img):
    frame = img.copy()
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # ====== Red Detection ======
    lower1, upper1 = np.array([0, 50, 40]), np.array([15, 255, 255])
    lower2, upper2 = np.array([160, 50, 40]), np.array([180, 255, 255])
    mask1 = cv2.inRange(hsv, lower1, upper1)
    mask2 = cv2.inRange(hsv, lower2, upper2)
    red_mask = cv2.bitwise_or(mask1, mask2)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))

    red_center = None
    cnts, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if cnts:
        c = max(cnts, key=cv2.contourArea)
        (rx, ry), rr = cv2.minEnclosingCircle(c)
        if rr > 3:
            red_center = (int(rx), int(ry))

    # ====== Green Detection ======
    v_mean = np.mean(hsv[:, :, 2])
    if v_mean > 180:
        s_min, v_min = 10, 40
        h_low, h_high = 25, 95
    elif v_mean < 80:
        s_min, v_min = 40, 30
        h_low, h_high = 35, 90
    else:
        s_min, v_min = 25, 35
        h_low, h_high = 30, 90

    green_mask = cv2.inRange(hsv, np.array([h_low, s_min, v_min]), np.array([h_high, 255, 255]))
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))

    green_center = None
    cnts, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if cnts:
        # Ù…Ø±Ú©Ø² Ø³Ø¨Ø² Ø±Ø§ Ø¬Ø¯Ø§ Ø§Ø² Ù‚Ø±Ù…Ø² Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù† (Ø¯Ø± ÙØ§ØµÙ„Ù‡ Ù…Ø¹Ù‚ÙˆÙ„)
        possible_centers = []
        for c in cnts:
            (gx, gy), gr = cv2.minEnclosingCircle(c)
            if gr > 3:
                possible_centers.append((int(gx), int(gy)))

        if red_center is not None and possible_centers:
            # Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† ÛŒØ§ Ø¯ÙˆØ±ØªØ±ÛŒÙ† Ù†Ù‚Ø·Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚Ø±Ù…Ø² (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ÛŒÚ©ÛŒ Ø³Ø¨Ø² Ø§Ø³Øª)
            dists = [np.linalg.norm(np.array(red_center) - np.array(pt)) for pt in possible_centers]
            green_center = possible_centers[np.argmax(dists)]  # Ø¯ÙˆØ±ØªØ±ÛŒÙ† Ø¯Ø§ÛŒØ±Ù‡ Ø±Ø§ Ø³Ø¨Ø² ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…

    return red_center, green_center




def find_token_center1(img, color):
  hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
  if color == "green":
    v_mean = np.mean(hsv[:, :, 2])  # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ ØªØµÙˆÛŒØ±

    if v_mean > 180:   # Ù†ÙˆØ± Ø²ÛŒØ§Ø¯ â†’ Ø³Ø¨Ø² Ø±ÙˆØ´Ù† ÛŒØ§ ÙØ³ÙØ±ÛŒ
        s_min, v_min = 10, 40
        h_low, h_high = 25, 95
    elif v_mean < 80:  # Ù†ÙˆØ± Ú©Ù… â†’ Ø³Ø¨Ø² ØªÛŒØ±Ù‡
        s_min, v_min = 40, 30
        h_low, h_high = 35, 90
    else:              # Ù†ÙˆØ± Ù…Ø¹Ù…ÙˆÙ„ÛŒ
        s_min, v_min = 25, 35
        h_low, h_high = 30, 90

    lower = np.array([h_low, s_min, v_min])
    upper = np.array([h_high, 255, 255])
    mask = cv2.inRange(hsv, lower, upper)


  else:  # ğŸ”´ Red
     # Ø¯Ùˆ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚Ø±Ù…Ø² (Ù‚Ø±Ù…Ø² ØªÛŒØ±Ù‡ Ùˆ Ù‚Ø±Ù…Ø² Ø±ÙˆØ´Ù†)
      lower1 = np.array([0, 50, 40])
      upper1 = np.array([15, 255, 255])
      lower2 = np.array([160, 50, 40])
      upper2 = np.array([180, 255, 255])
    # âœ… ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ù…Ø§Ø³Ú©â€ŒÙ‡Ø§ Ø±Ùˆ ØªØ±Ú©ÛŒØ¨ Ú©Ù†
      mask1 = cv2.inRange(hsv, lower1, upper1)
      mask2 = cv2.inRange(hsv, lower2, upper2)
      mask = cv2.bitwise_or(mask1, mask2)

# ==============================
# ğŸ§¹ ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ù…Ø§Ø³Ú© Ùˆ Ø­Ø°Ù Ù†ÙˆÛŒØ²
# ==============================
  kernel = np.ones((5, 5), np.uint8)
  mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)   # Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ÛŒ Ú©ÙˆÚ†Ú© 
  mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel) # Ù¾Ø± Ú©Ø±Ø¯Ù† Ù†ÙˆØ§Ø­ÛŒ Ù†Ø§Ù‚Øµ

# ==============================
# ğŸŸ¢ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†ØªÙˆØ± Ø±Ù†Ú¯
# ==============================
  cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

  if cnts:
        c = max(cnts, key=cv2.contourArea)
        M = cv2.moments(c)
        area = cv2.contourArea(c)
        if M["m00"] != 0 and area > 0:
            cx, cy = int(M["m10"]/M["m00"]), int(M["m01"]/M["m00"])
            r = int(max(8, np.sqrt(area/np.pi)))
            return (cx, cy), mask, r
  return None, mask, None

#======================================================================
def remove_tokens_from_binary(binary, centers_radii, margin=6):
    cleaned = binary.copy()
    for (cx, cy, r) in centers_radii:
        if cx and cy and r:
            R = int(r + margin)
            cv2.circle(cleaned, (cx, cy), R, (0, 0, 0), -1)
    return cleaned
#======================================================================
def pixel_to_dobot(x_px, y_px):
    # âš™ï¸ Ø§Ø¨Ø¹Ø§Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ Ù…Ø§Ø² Ø±ÙˆÛŒ Ù…ÛŒØ² (Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±)
    MAZE_MM_X = 200
    MAZE_MM_Y = 220

    # ğŸ§­ Ù…Ø±Ú©Ø² Ù…Ø§Ø² Ø±ÙˆÛŒ Ù…ÛŒØ² (Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±)
   # ORIGIN_XY = (290, 0)

    # ğŸ“ Ù†Ø³Ø¨Øª ØªØ¨Ø¯ÛŒÙ„ Ù¾ÛŒÚ©Ø³Ù„ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ±
    SCALE_X = MAZE_MM_X / WARP_SIZE_X
    SCALE_Y = MAZE_MM_Y / WARP_SIZE_Y

    # ğŸ”„ ØªØ¨Ø¯ÛŒÙ„ Ù…Ø®ØªØµØ§Øª Ù¾ÛŒÚ©Ø³Ù„ Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª Ø±Ø¨Ø§Øª
    X = ORIGIN_XY[0] + (y_px - WARP_SIZE_X/2) * SCALE_X
    Y = ORIGIN_XY[1] + (x_px - WARP_SIZE_Y/2) * SCALE_Y
    print("X=",X," ","y=",Y," ","x=",y_px,"y=",x_px)
    return X, Y, PATH_Z


# =================== Calibration ===================
_calib_pts = []
def _on_mouse(event, x, y, flags, param):
    global _calib_pts
    if event == cv2.EVENT_LBUTTONDOWN and len(_calib_pts) < 4:
        _calib_pts.append((x, y))
        print(f"[Calib] Point {len(_calib_pts)}: ({x}, {y})")
#======================================================================
def calibrate_board(cap):
    global _calib_pts
    _calib_pts = []
    win = "Board Calib"
    cv2.namedWindow(win)
    cv2.setMouseCallback(win, _on_mouse)
    print("[Calib] Click 4 corners TL, TR, BR, BL then press Enter.")

    while True:
        ok, frame = cap.read()
        if not ok:
            continue
        disp = frame.copy()
        for i, p in enumerate(_calib_pts):
            cv2.circle(disp, p, 6, (0, 255, 255), -1)
            cv2.putText(disp, str(i + 1), (p[0] + 5, p[1] - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        cv2.imshow(win, disp)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('c'):
            _calib_pts = []
        elif key == ord('q'):
            cv2.waitKey(100)
  
            cv2.destroyWindow(win)
            return None
        elif key in (13, 10) and len(_calib_pts) == 4:
            #src = np.array(_calib_pts, dtype=np.float32)
            
          # src = np.array([[0, 0], [WARP_SIZE_X, 0],
          #                  [WARP_SIZE_X, WARP_SIZE_Y], [0, WARP_SIZE_Y]], dtype=np.float32)
           
            src = np.array([[WARP_SIZE_X, WARP_SIZE_Y], [0, WARP_SIZE_Y],
                            [0, 0], [WARP_SIZE_X, 0]], dtype=np.float32)    
            dst = np.array([[0, 0], [WARP_SIZE_X, 0],
                            [WARP_SIZE_X, WARP_SIZE_Y], [0, WARP_SIZE_Y]], dtype=np.float32)
            M = cv2.getPerspectiveTransform(src, dst)
            np.save("calibration_matrix.npy", M)
            print("[Calib] Saved calibration to calibration_matrix.npy")
            cv2.destroyAllWindows()
            cv2.waitKey(100)
   

            return M
#======================================================================
def load_calibration():
    try:
        M = np.load("calibration_matrix.npy")
        print("[Calib] Loaded existing calibration.")
        return M
    except Exception:
        print("[Calib] No saved file found.")
        return None
#======================================================================
def calibrate_Papar(cap):
    global _calib_pts
    _calib_pts = []
    win = "Board Calib"
    cv2.namedWindow(win)
    cv2.setMouseCallback(win, _on_mouse)
    print("[Calib] Click 4 corners TL, TR, BR, BL then press Enter.")

    while True:
        ok, frame = cap.read()
        if not ok:
            continue
        disp = frame.copy()
        
        cv2.imshow(win, disp)
        key = cv2.waitKey(1) & 0xFF
        if key == 27:
           break
             
    cv2.destroyWindow(win)
    return key
 

# ============ ArUco Detection ============
def detect_aruco_markers(cap, needed_ids=(0,1,2,3)):
    try:
        aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
        parameters = cv2.aruco.DetectorParameters()
        detector = cv2.aruco.ArucoDetector(aruco_dict, parameters)
        use_new = True
    except:
        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)
        parameters = cv2.aruco.DetectorParameters_create()
        use_new = False

    centers = {}
    print("ğŸ¯ Detecting 4 ArUco markers (IDs 0,1,2,3)... Press ESC to continue.")

    while True:
        ok, frame = cap.read()
        if not ok:
            continue

        # ğŸŒ€ Flip 180Â° before processing
        frame = cv2.rotate(frame, cv2.ROTATE_180)

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        if use_new:
            corners, ids, _ = detector.detectMarkers(gray)
        else:
            corners, ids, _ = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

        if ids is not None:
            ids = ids.flatten()
            for i, marker_id in enumerate(ids):
                if marker_id in needed_ids:
                    c = corners[i][0]
                    center = c.mean(axis=0)
                    centers[marker_id] = center
                    cv2.polylines(frame, [c.astype(int)], True, (0,255,0), 2)
                    cv2.putText(frame, f"ID {marker_id}",
                                tuple(c[0].astype(int)),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

        cv2.imshow("ArUco Detection", frame)
        k = cv2.waitKey(1) & 0xFF
        if k == 27:
            break

    cv2.destroyWindow("ArUco Detection")
    if len(centers) < 4:
        print(f"âš ï¸ Only {len(centers)} markers detected. Make sure all 4 are visible.")
    else:
        print("âœ… All 4 markers detected.")
    return centers

#======================================================================
 # --- Convert pixel to robot coordinates ---
def image_to_robot(x_img, y_img):
        global H
        p = np.array([[[x_img, y_img]]], dtype=float)
        p_r = cv2.perspectiveTransform(p, H)[0][0]
        return p_r[0], p_r[1],PATH_Z
#======================================================================
def getkey():
    while True:
        k = cv2.waitKey(1) & 0xFF
        if ord('a') <= k <= ord('z') or k in [13, 27]:
            break
# ============================ Robot Driver ===========================
def Get_calibrate_H(cap):
     # --- Calibration / Load existing homography ---
    global H, device, mask   # ğŸ‘ˆ Ø§Ø¹Ù„Ø§Ù… Ø§ÛŒÙ†Ú©Ù‡ Ø§Ø² Ù†Ø³Ø®Ù‡â€ŒÛŒ global Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    
    # --- Calibration / Load existing homography ---
    if os.path.exists(SAVE_FILE):
        print(f"ğŸ“ Calibration file found: {SAVE_FILE}")
        with open(SAVE_FILE, "r") as f:
            data = json.load(f)
        H = np.array(data["homography"], dtype=float)
        print("âœ… Calibration file loaded successfully.")
    else:
        centers = detect_aruco_markers(cap)
        if len(centers) < 4:
            print("âš ï¸ Not all 4 markers detected. Exiting.")
            return

        aruco_real = {}
        for marker_id in [0,1,2,3]:
            input(f"\nğŸ‘‰ Move the robot tool tip to the center of ArUco ID={marker_id} and press Enter...")
            pose, _ = device.get_pose()
            x, y, z, r = pose
            aruco_real[marker_id] = np.array([x, y], dtype=float)
            print(f"ğŸ“ Real coordinates for marker {marker_id}: {aruco_real[marker_id].tolist()}")

        device.move_to(*HOME)

        img_pts = np.array([centers[i] for i in sorted(centers.keys())], dtype=float)
        real_pts = np.array([aruco_real[i] for i in sorted(aruco_real.keys())], dtype=float)
        H, mask = cv2.findHomography(img_pts, real_pts, cv2.RANSAC, 2.0)
        print(f"âœ… Homography computed ({int(mask.sum())}/{len(mask)} inliers).")

        data = {
            "homography": H.tolist(),
            "aruco_img_pts": img_pts.tolist(),
            "aruco_real_pts": real_pts.tolist()
        }
        with open(SAVE_FILE, "w") as f:
            json.dump(data, f, indent=2)
        print(f"ğŸ’¾ Calibration data saved to {SAVE_FILE}.")
#-------------------------------------------------------------------------
def Clean_Nois(binary):
    # Ø­Ø°Ù Ù†ÙˆÛŒØ²Ù‡Ø§ Ùˆ Ø®Ø·ÙˆØ· Ù†Ø§Ø²Ú©
    kernel_thick = np.ones((3, 3), np.uint8)  # Ù‡Ø³ØªÙ‡â€ŒÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¸Ø±Ø§ÙØª Ø¨ÛŒØ´ØªØ±

# Ø§Ø¨ØªØ¯Ø§ Ù†ÙˆÛŒØ² Ùˆ Ù†Ù‚Ø§Ø· Ú©ÙˆÚ†Ú© Ø­Ø°Ù Ù…ÛŒâ€ŒØ´Ù†
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_thick, iterations=1)

# Ø¨Ø¹Ø¯ Ø¨Ø§ erode Ø®Ø·ÙˆØ· Ù†Ø§Ø²Ú©â€ŒØªØ± Ø§Ø² 2 Ù¾ÛŒÚ©Ø³Ù„ Ø­Ø°Ù Ù…ÛŒâ€ŒØ´Ù†
    binary = cv2.erode(binary, kernel_thick, iterations=1)

# Ø­Ø§Ù„Ø§ Ø´Ú©Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ Ù¾Ø± Ù…ÛŒâ€ŒØ´Ù† ØªØ§ Ø³Ø§Ø®ØªØ§Ø± Ø§ØµÙ„ÛŒ Ù…Ø§Ø² Ø³Ø§Ù„Ù… Ø¨Ù…ÙˆÙ†Ù‡
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_thick, iterations=2)
    return binary
#--------------------------------------------------------------------
def Clean_Nois2(binary):
# Ø­Ø°Ù Ù†ÙˆÛŒØ² Ø¨Ø¯ÙˆÙ† Ù†Ø§Ø²Ú© Ø´Ø¯Ù† Ø¯ÛŒÙˆØ§Ø±Ù‡Ø§
 num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity=8)
 sizes = stats[1:, -1]
 min_size = 150
 binary_clean = np.zeros_like(binary)
 for i in range(0, num_labels - 1):
     if sizes[i] >= min_size:
         binary_clean[labels == i + 1] = 255
 binary = binary_clean
 return binary
#-----------------------------------------------------
def Delet_space(binary, gates, gate_radius=300):
   
    img = (binary > 127).astype(np.uint8) * 255
    h, w = img.shape
    visited = np.zeros((h, w), np.uint8)

    # Ø³Ø§Ø®Øª Ù…Ø§Ø³Ú© Ù…Ø­Ø§ÙØ¸ Ø¨Ø±Ø§ÛŒ GateÙ‡Ø§
    protect_mask = np.zeros_like(img)
    for (gy, gx) in gates:
        cv2.circle(protect_mask, (int(gx), int(gy)), gate_radius, 255, -1)

    q = deque()

    # Ø§Ø² Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ§Ù‡ Ø¯Ø± Ù…Ø±Ø² Ø´Ø±ÙˆØ¹ Ú©Ù†
    for x in range(w):
        if img[0, x] == 0: q.append((0, x))
        if img[h-1, x] == 0: q.append((h-1, x))
    for y in range(h):
        if img[y, 0] == 0: q.append((y, 0))
        if img[y, w-1] == 0: q.append((y, w-1))

    # BFS Ø¨Ø±Ø§ÛŒ Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¨ÛŒØ±ÙˆÙ†
    while q:
        y, x = q.popleft()
        if y < 0 or y >= h or x < 0 or x >= w:
            continue
        if visited[y, x]:
            continue
        if img[y, x] == 255:
            continue
        if protect_mask[y, x] == 255:   # Ø§Ú¯Ø± Ù†Ø²Ø¯ÛŒÚ© Gate Ø¨ÙˆØ¯ØŒ Ù¾Ø± Ù†Ú©Ù†
            continue

        visited[y, x] = 1
        img[y, x] = 255  # Ø¨ÛŒØ±ÙˆÙ† â†’ Ø³ÙÛŒØ¯

        q.append((y-1, x))
        q.append((y+1, x))
        q.append((y, x-1))
        q.append((y, x+1))

    return img
import cv2
import numpy as np

def remove_circles(img, red_center, green_center, radius=20):
    """
    Ø­Ø°Ù Ø¯Ùˆ Ø¯Ø§ÛŒØ±Ù‡ (Ù‚Ø±Ù…Ø² Ùˆ Ø³Ø¨Ø²) Ø§Ø² ØªØµÙˆÛŒØ± Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ
    
    Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
        img: ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ (BGR)
        red_center: Ù…Ø®ØªØµØ§Øª Ù…Ø±Ú©Ø² Ø¯Ø§ÛŒØ±Ù‡ Ù‚Ø±Ù…Ø² (x, y)
        green_center: Ù…Ø®ØªØµØ§Øª Ù…Ø±Ú©Ø² Ø¯Ø§ÛŒØ±Ù‡ Ø³Ø¨Ø² (x, y)
        radius: Ø´Ø¹Ø§Ø¹ Ù†Ø§Ø­ÛŒÙ‡â€ŒØ§ÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ù¾Ø§Ú© Ø´ÙˆØ¯ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 20 Ù¾ÛŒÚ©Ø³Ù„)
    """
    frame = img.copy()
    h, w= frame.shape

    # Ø±Ù†Ú¯ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø±Ø§ Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø·Ø±Ø§Ù Ø¨Ú¯ÛŒØ±
    bg_color = np.mean(frame, axis=(0,1)).astype(np.uint8)

    # Ø§Ú¯Ø± Ù…Ø±Ú©Ø² Ù‚Ø±Ù…Ø² Ù…Ø´Ø®Øµ Ø§Ø³Øª
    if red_center is not None:
        cv2.circle(frame, red_center, radius, bg_color.tolist(), -1)

    # Ø§Ú¯Ø± Ù…Ø±Ú©Ø² Ø³Ø¨Ø² Ù…Ø´Ø®Øµ Ø§Ø³Øª
    if green_center is not None:
        cv2.circle(frame, green_center, radius, bg_color.tolist(), -1)

    return frame


#-----------------------------------------------------------------------

def get_frame_from_file(path):
    """
    ÛŒÚ© ØªØµÙˆÛŒØ± Ø§Ø² ÙØ§ÛŒÙ„ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯ Ùˆ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© ÙØ±ÛŒÙ… Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯: (ret, frame) ØªØ§ Ø´Ø¨ÛŒÙ‡ Ø¨Ù‡ cv2.VideoCapture.read Ø±ÙØªØ§Ø± Ú©Ù†Ø¯.
    """
    if not os.path.exists(path):
        return False, None

    frame = cv2.imread(path, cv2.IMREAD_COLOR)  # BGR
    if frame is None:
        return False, None
    return True, frame

#-----------------------------------------------------------------------------
def radial_roundness(cnt, center):
    """ Ù†Ø³Ø¨Øª std/mean ÙØ§ØµÙ„Ù‡Ù” Ù†Ù‚Ø§Ø· Ú©Ø§Ù†ØªÙˆØ± ØªØ§ Ù…Ø±Ú©Ø² Ø¯Ø§ÛŒØ±Ù‡ """
    cx, cy = center
    pts = cnt.reshape(-1, 2)
    d = np.sqrt((pts[:,0]-cx)**2 + (pts[:,1]-cy)**2)
    if d.size < 10: 
        return 1.0
    return float(np.std(d) / (np.mean(d) + 1e-6))

def detect_circles_shape_first(img, min_r=14, max_r=60):
    """
    ÙÙ‚Ø· Ø¯Ø§ÛŒØ±Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯Ø›
    Ø®Ø±ÙˆØ¬ÛŒ: [(x, y, r, color)]
    """
    vis = img.copy()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5,5), 0)

    # Ù„Ø¨Ù‡â€ŒÙ‡Ø§ + Ø¨Ø³ØªÙ† Ø´Ú©Ø§Ùâ€ŒÙ‡Ø§
    edges = cv2.Canny(blur, 60, 140)
    edges = cv2.dilate(edges, np.ones((3,3), np.uint8), 1)
    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8), iterations=1)

    # Ú©Ø§Ù†ØªÙˆØ±Ù‡Ø§ Ø¨Ø§ Ø³Ù„Ø³Ù„Ù‡â€ŒÙ…Ø±Ø§ØªØ¨
    contours, hierarchy = cv2.findContours(edges, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if hierarchy is None:
        return []

    results = []
    for i, cnt in enumerate(contours):
        # ÙÙ‚Ø· Ú©Ø§Ù†ØªÙˆØ±Ù‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ø¨Ú†Ù‡ (hierarchy[0][i][2] == -1)
        if hierarchy[0][i][2] != -1:
            continue

        area = cv2.contourArea(cnt)
        if area < 120:
            continue

        (cx, cy), r = cv2.minEnclosingCircle(cnt)
        r = float(r)
        if r < min_r or r > max_r:
            continue

        # Ú†Ù†Ø¯Ø¶Ù„Ø¹ÛŒâ€ŒØ¨ÙˆØ¯Ù†Ø› Ù…Ø±Ø¨Ø¹â€ŒÙ‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ~4 Ø±Ø£Ø³ Ø¯Ø§Ø±Ù†Ø¯
        eps = 0.02 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, eps, True)
        if len(approx) <= 3:      # Ù…Ø«Ù„Ø«/Ø´Ú©Ù„ ØªÛŒØ²
            continue
        if len(approx) == 4:      # Ù…Ø±Ø¨Ø¹/Ù…Ø³ØªØ·ÛŒÙ„ â†’ Ø±Ø¯
            continue

        # Ú¯Ø±Ø¯ÛŒ (circularity)
        per = cv2.arcLength(cnt, True)
        circularity = 4 * math.pi * (area / (per*per + 1e-6))
        if circularity < 0.78:
            continue

        # Ø³Ù†Ø¬Ù‡Ù” Ø¯Ø§ÛŒØ±Ù‡â€ŒØ¨ÙˆØ¯Ù† Ø´Ø¹Ø§Ø¹ÛŒ (Ø®ÛŒÙ„ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù…Ø±Ø¨Ø¹)
        rr = radial_roundness(cnt, (cx, cy))
        if rr > 0.12:  # Ù‡Ø±Ú†Ù‡ Ú©ÙˆÚ†Ú©â€ŒØªØ± â†’ Ø¯Ø§ÛŒØ±Ù‡â€ŒØªØ± (0.05~0.12 Ù…Ù†Ø§Ø³Ø¨)
            continue

        # --- ÙÙ‚Ø· Ø­Ø§Ù„Ø§ Ø±Ù†Ú¯ Ø±Ø§ Ø¨Ø±Ú†Ø³Ø¨ Ù…ÛŒâ€ŒØ²Ù†ÛŒÙ… ---
        mask = np.zeros_like(gray)
        cv2.circle(mask, (int(cx), int(cy)), int(r), 255, -1)
        b, g, rv = cv2.mean(img, mask=mask)[:3]
        v = (b+g+rv)/3.0
        if rv > g + 35 and rv > b + 35:
            color = "red";   col = (0,0,255)
        elif g > rv + 35 and g > b + 35:
            color = "green"; col = (0,255,0)
        elif v < 65:
            color = "black"; col = (0,0,0)
        else:
            color = "unknown"; col = (255,255,0)

        # Ø±Ø³Ù… Ø®Ø±ÙˆØ¬ÛŒ
        cv2.circle(vis, (int(cx), int(cy)), int(r), col, 3)
        cv2.circle(vis, (int(cx), int(cy)), 2, (255,255,255), -1)
        cv2.putText(vis, color, (int(cx)-22, int(cy)-int(r)-8),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)

        results.append((int(cx), int(cy), int(r), color))

    return results, vis

# =================== Solve Maze ===================
def solve_maze_and_get_path(run_robot):
    global H, device, mask,start_color 

    #start_color = "green"
    end_color = "red" if start_color == "green" else "green"
#---------------------------------------------
    if run_robot and Dobot is not None:
        device = Dobot(port=DOBOT_PORT)
        device.speed(SPEED_XY, SPEED_Z)
        device.move_to(*HOME)
#---------------------------------------------
    
    cap = cv2.VideoCapture(CAMERA_PORT)
    time.sleep(2)
    Get_calibrate_H(cap)
#---------------------------------------------
    M = load_calibration()
    if M is None:
        M = calibrate_board(cap)
        if M is None:
            print("âŒ Calibration failed.")
            return
#---------------------------------------------

    calibrate_Papar(cap)
    ret, img = cap.read()
    if not ret:
        print("âŒ Camera not available.")
        return
#---------------------------------------------
    if FlagFileImag==1:
      ret, img = get_frame_from_file("/home/mohammadreza/Desktop/Mazi/AIVoice/2.jpg")
      if not ret:
        print("Ø®Ø·Ø§: ÙØ§ÛŒÙ„ Ø¨Ø§Ø² Ù†Ø´Ø¯.")  
      else:
         cv2.imshow("frame", img)
         cv2.waitKey(0)
         cv2.destroyAllWindows()
    
#---------------------------------------------
    # ğŸ”„ Warp Ø¨Ø§ ÙÛŒÙ„ØªØ± Ù†Ø±Ù… Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù†ÙˆÛŒØ² Ù„Ø¨Ù‡
    warped = cv2.warpPerspective(img, M, (WARP_SIZE_X, WARP_SIZE_Y))
    warped = cv2.GaussianBlur(warped, (3, 3), 0)
    cv2.imshow("Warped Maze", warped)
    getkey()
#---------------------------------------------
    
    circles, out = detect_circles_shape_first(warped)
    print("âœ… Ø¯Ø§ÛŒØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ:")
    for c in circles:
        print(c)

    #cv2.circle(vis, (int(cx), int(cy)), int(r), col, 3)     
   # cv2.imshow("Circles (shape-only, anti-square)", out)
  #  cv2.waitKey(0)
   # cv2.destroyAllWindows()

    if len(circles)>1 :
     for (x, y, r, color) in circles:
      if color == "red":
         red_center = (x, y)
         r_Red=r
      else :
         green_center = (x, y)
         r_Green=r
    else :
        start, _, r_start = find_token_center(warped, start_color)
        print(start)
        end, _, r_end = find_token_center(warped, end_color)
        print(end)
        if not start or not end:
           print("âŒ Could not detect both Stat And ENd.")
           return
    if len(circles)>1 :
     if start_color=="red" :
       start= red_center 
       r_start=r_Red
       end =green_center 
       r_end =r_Green
     else :
       start= green_center 
       r_start=r_Green
       end =red_center 
       r_end = r_Red
    
    cv2.circle(warped, (int(start[0]), int(start[1])), int(r_start), (255,255,255), 3)     
    cv2.imshow("Circles test", warped)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

#---------------------------------------------
    gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)
    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)
    binary = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                   cv2.THRESH_BINARY_INV, 15, 4)

    kernel = np.ones((KERNEL_SIZE, KERNEL_SIZE), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    binary = cv2.dilate(binary, kernel, iterations=DILATE_ITER)
  #---------------------------------------------

  #---------------------------------------------
    # ğŸ§¹ Ø­Ø°Ù ØªÙˆÚ©Ù†â€ŒÙ‡Ø§

    cv2.circle(binary, (int(start[0]), int(start[1])), int(r_start), (255,255,255), 3)     
    cv2.imshow("Circles test", binary)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    cleaned = remove_tokens_from_binary(binary, [(start[0], start[1], r_start),
                                            (end[0], end[1], r_end)], margin=Margin_for_delet)
    #cleaned= remove_circles(binary, start, end, radius=25)
    #cleaned= binary
   #--------------------------------------------- 
    cleaned=Clean_Nois2(cleaned)
    cleaned=Clean_Nois2(cleaned)
    cleaned=Clean_Nois2(cleaned)
   

#---------------------------------------------
    cv2.imshow("Binary Maze Cleaned", cleaned)
    getkey()
    sy, sx, ey, ex = start[1], start[0], end[1], end[0]
    #--------------------------------------------- 
    gates = [(sy, sx), (ey, ex)]
    cleaned=Delet_space(cleaned, gates , 200)
    
#---------------------------------------------
    maze = (cleaned // 255).astype(np.uint8)
    sy, sx, ey, ex = start[1], start[0], end[1], end[0]
    if maze[sy, sx] == 0 or maze[ey, ex] == 0:
        maze = 1 - maze
   
    maze2=(maze * 255).astype(np.uint8) 
    cv2.imshow(" Maze array", maze2)
    cv2.waitKey(0)
    cv2.destroyAllWindows()  
#---------------------------------------------
    # âš™ï¸ ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù†ÛŒ
    SAFE_MARGIN_PX = 12
    CENTER_WEIGHT = 8.0
    REPULSION_STRENGTH = 15

    # ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… A*
    path, dist = astar_safe(maze, (sy, sx), (ey, ex))
    
    if not path:
        print("âŒ No path found.")
        return

    # ğŸ”„ ØµØ§Ùâ€ŒÚ©Ø±Ø¯Ù† Ùˆ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±
    path = smooth_path(path, window=SMOOTH_WINDOW)
    path_comp = compress_straight_segments(path)

    # ğŸ§® ØªØ¨Ø¯ÛŒÙ„ Ù…Ø³ÛŒØ± Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª Ø±Ø¨Ø§Øª
    dobot_path = [image_to_robot(x, y) for (y, x) in path_comp]

    # ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø³ÛŒØ± Ø§ÛŒÙ…Ù†
    with open("dobot_path_safe.csv", "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["X_mm", "Y_mm", "Z_mm"])
        writer.writerows(dobot_path)
    print("âœ… Saved safe path to dobot_path_safe.csv")

    # ğŸ”´ Ù†Ù…Ø§ÛŒØ´ Ù…Ø³ÛŒØ± Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±
    solved = warped.copy()
    for (y, x) in path:
        cv2.circle(solved, (x, y), 1, (0, 0, 255), -1)
    cv2.imshow("Solved Maze (Safe Path)", solved)
    getkey()

    # ğŸ® Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ÛŒØ± Ø²Ù†Ø¯Ù‡ Ø¨Ø§ Ø±Ø¨Ø§Øª
    ports = list(serial.tools.list_ports.comports())
    if not ports:
        print("âš ï¸ No Dobot connected â€” skipping live execution.")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return

    try:
        for i, (x, y, z) in enumerate(dobot_path):
            device.move_to(x, y, Z_Safe, r=0)
            py, px = path_comp[i]
            cv2.circle(solved, (px, py), 4, (0, 255, 255), -1)
            cv2.imshow("Live Path Follow", solved)
            if cv2.waitKey(1) == 27:
                break
            time.sleep(0.05)
        device.move_to(*HOME)
        device.close()
        print("âœ… Path executed safely!")
    except Exception as e:
        print(f"âš ï¸ Error executing path: {e}")

    cv2.waitKey(0)
    cv2.destroyAllWindows()
    cap.release()

# ======= Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API =======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)
elevenlabs = ElevenLabs(api_key=ELEVENLABS_API_KEY)

# ======= Ú¯ÙØªØ§Ø± Ø¨Ù‡ ØµØ¯Ø§ (ElevenLabs) =======
def speak(text1):
    global Flag_Voice_Text

    print(f"ğŸ¤– Speaking: {text1}")
    
    if Flag_Voice_Text==1 :
        audio = elevenlabs.text_to_speech.convert(
        text=text1,
        voice_id="pqHfZKP75CvOlQylNhV4",
        model_id="eleven_multilingual_v2",
        output_format="mp3_44100_128",)
        play(audio)
    else  :
        print(text1)

# ======= Ú¯ÙØªØ§Ø± Ø¨Ù‡ Ù…ØªÙ† (Whisper) =======
def listen_whisper():
  global Flag_Voice_Text
  
  if Flag_Voice_Text==1 :
    print("ğŸ§ Listening... Speak now.")

    audio = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype="int16")
    sd.wait()

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
        write(tmpfile.name, SAMPLE_RATE, audio)
        tmp_path = tmpfile.name

    with open(tmp_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
        )

    text = transcript.text.strip()
    print(f"ğŸ‘¤ You said: {text}")
  else :
    text=""
    print("ğŸ§ Pleas Enter Your Command ? ")
    text=input()
  return text.lower()

# ======= ØªØ§Ø¨Ø¹ ØªØ´Ø®ÛŒØµ ÙØ±Ù…Ø§Ù† =======
def detect_command(text):
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± Ú©Ù„Ù…Ù‡ playØŒ redØŒ ÛŒØ§ green Ø±Ø§ Ú¯ÙØªÙ‡ Ø§Ø³Øª
    """
    text = text.lower().strip()

    patterns = {
        "green": [r"\bgreen\b", "Ø³Ø¨Ø²"],
        "red": [r"\bred\b", "Ù‚Ø±Ù…Ø²"],
        "play": [r"\bplay\b", "Ù¾Ù„ÛŒ", "Ø´Ø±ÙˆØ¹"],
        "exit" :[r"\bexit\b"],
        "algorithm" :[r"\bexit\b"]
    }

    for key, words in patterns.items():
        for w in words:
            if re.search(w, text):
                return key

    return None

# ======= Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ =======
def Greeting():
    global TextGlobal, State
    print("ğŸ§© Greeting")
    speak("Welcome! I am your maze assistant. how can i help you")
    State = 2

def Record1():
    global TextGlobal, State
    print("ğŸ™ï¸ Recording user command...")
    TextGlobal = listen_whisper()
    State = 3

# âœ… Ù†Ø³Ø®Ù‡ Ø¬Ø¯ÛŒØ¯ ØªØ§Ø¨Ø¹ Check_Word Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ†
def Chek_Word():
    global TextGlobal, State, start_color
    print("ğŸ§  Checking words with GPT intent detection...")

    if not TextGlobal:
        speak("I didnâ€™t hear you. Please say play or choose a color.")
        State = 2
        return

    try:
        # ğŸ’¬ Ù…Ø±Ø­Ù„Ù‡ Û±: ÙØ±Ø³ØªØ§Ø¯Ù† Ø¬Ù…Ù„Ù‡â€ŒÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ ChatGPT Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù‡Ø¯Ù
        prompt = f"""
        You are an intent classification assistant.
        The user said: "{TextGlobal}"

        Your task is to classify the user's intent into one of these actions:
        [play, stop, explain, red, green, algorithm, exit, none]

        - "play" â†’ user wants to play the maze.
        - "stop" â†’ user doesn't want to play.
        - "explain" â†’ user wants you to explain something about the game.
        - "red"/"green" â†’ user chose a starting color.
        - "algorithm" â†’ user asked about A* or the maze-solving method.
        - "exit" â†’ user wants to end the presentation.
        - "none" â†’ uncertain intent.

        Respond **only with one word** from the list above.
        """

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": prompt}]
        )

        intent = response.choices[0].message.content.strip().lower()
        print(f"ğŸ¯ GPT detected intent: {intent}")

        # ğŸ’¡ Ù…Ø±Ø­Ù„Ù‡ Û²: ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ intent
        if intent == "play":
            #speak("You want to play. Please choose a color: red or green.")
            State = 6

        elif intent == "red":
            speak("You chose red. Starting from the red point.")
            start_color = "red"
            State = 7

        elif intent == "green":
            speak("You chose green. Starting from the green point.")
            start_color = "green"
            State = 7

        elif intent == "algorithm":
            speak("You asked about the algorithm. Let me explain the A-star pathfinding method.")
            TextGlobal = "Explain how the A* algorithm solves the maze."
            State = 4  # Ø¨Ø±Ùˆ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØ¶ÛŒØ­ Ø§Ø² GPT

        elif intent == "explain":
            speak("Sure, I will explain how this maze system works.")
            TextGlobal = "Explain how this maze system works."
            State = 4

        elif intent == "stop":
            speak("Okay, we will not play right now.")
            State = 1  # Ø¨Ø±Ú¯Ø±Ø¯ Ø¨Ù‡ Ø­Ø§Ù„Øª Ø§ÙˆÙ„ ÛŒØ§ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ¨Ù‡â€ŒÚ©Ø§Ø±

        elif intent == "exit":
           # speak("Presentation finished. Thank you for listening!")
            State = 8

        else:
           # speak("I didnâ€™t clearly understand. Could you please repeat?")
            State = 4  # Ø¨Ø±Ú¯Ø±Ø¯ Ø¨Ù‡ Ø¶Ø¨Ø· Ù…Ø¬Ø¯Ø¯

    except Exception as e:
        print(f"âŒ Error in Chek_Word: {e}")
        #speak("Sorry, I had trouble understanding. Please try again.")
        State = 6

#-----------------------------------------------------------------------
def Get_Answer():
    global TextGlobal, State
    print("ğŸ§© Getting answer from ChatGPT...")

    if not TextGlobal or TextGlobal=="you" :
        speak("I didnâ€™t receive any text yet. Please say something first.")
        State = 2
        return

    try:
        # Ù¾ÛŒØ§Ù… Ø¨Ù‡ ChatGPT
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are an AI maze assistant who explains clearly and briefly."},
                {"role": "user", "content": TextGlobal},
            ],
        )

        # Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± TextGlobal
        answer = response.choices[0].message.content.strip()
        TextGlobal = answer[:200]

        print(f"ğŸ¤– GPT Response: {answer}")
        #speak("Hereâ€™s my answer for you.")
        #speak(answer)

        # Ø±ÙØªÙ† Ø¨Ù‡ Ø­Ø§Ù„Øª Ø¨Ø¹Ø¯ÛŒ
        State = 5

    except Exception as e:
        print(f"âŒ Error in Get_Answer: {e}")
        speak("I encountered an error while contacting ChatGPT.")
        State = 2


def Play_Answer():
    global TextGlobal, State
    speak("Hereâ€™s my answer for you.")
    speak(TextGlobal)
    State = 6  # Ø¨Ø±Ú¯Ø±Ø¯ Ø¨Ù‡ Ø´Ø±ÙˆØ¹ ÛŒØ§ Ø§Ø¯Ø§Ù…Ù‡

def Play_Want():
    global TextGlobal, State
    print("ğŸ§© Play_Want")
    speak("You wanted to play. Please say the color to start the maze: red or green.")
    State = 2

   
def StartMaze():
    global TextGlobal, State
    print("ğŸ§© Play_Want")
    speak("Start Play")
    solve_maze_and_get_path(run_robot=True)
    State = 6

def EndPlay():
    global TextGlobal, State
    print("ğŸ§© EndPlay")
    speak("Presentation finished. Thank you for listening! bye Have a good one")
    State = 1000
# ======= Ú¯Ø±Ø§Ù Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ =======
Machine_State_Graph = {
    1: {"Agent": Greeting},
    2: {"Agent": Record1},
    3: {"Agent": Chek_Word},
    4: {"Agent": Get_Answer},
    5: {"Agent": Play_Answer},
    6: {"Agent": Play_Want},
    7: {"Agent": StartMaze},
    8: {"Agent": EndPlay},
}

# ======= Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ =======
def main():
    global State,Flag_Exit
  
    while not Flag_Exit:
        if State in Machine_State_Graph:
            print(f"\nâ–¶ï¸ -----------------------Running state {State}")
           
            Machine_State_Graph[State]["Agent"]()
          
            time.sleep(1)
        else:
            Flag_Exit = 1

    #speak("Presentation finished. Thank you for listening!")

# ======= Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ =======
if __name__ == "__main__":
    main()

# =================== Run ===================
#if __name__ == "__main__":
 #   solve_maze_and_get_path(run_robot=True)
